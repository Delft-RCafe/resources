## Building Apps in R

* [Shiny from RStudio](https://shiny.rstudio.com/) - Shiny is an R package that makes it easy to build interactive web apps straight from R. You can host standalone apps on a webpage or embed them in R Markdown documents or build dashboards. You can also extend your Shiny apps with CSS themes, htmlwidgets, and JavaScript actions.
* [Mastering Shiny (book)](https://mastering-shiny.org/) - Build interactive apps, reports and dashboards powered by R
* [Flex Dashboard](https://pkgs.rstudio.com/flexdashboard/) - Easy interactive dashboards for R

## Building Websites in R

* [Blogdown](https://github.com/rstudio/blogdown) - Provides a powerful and customizable website output format for R Markdown
* [Binder](https://mybinder.org/) - Have a repository full of Jupyter notebooks? With Binder, open those notebooks in an executable environment, making your code immediately reproducible by anyone, anywhere.
* [Netlify](https://www.netlify.com/) - Build, deploy & scale modern web projects

## Dependency management

* [PackRat](https://rstudio.github.io/packrat/) - a dependency management system for R
* [renv](https://rstudio.github.io/renv/articles/renv.html) - a new effort to bring project-local R dependency management to your projects. The goal is for renv to be a robust, stable replacement for the Packrat package, with fewer surprises and better default behaviors.
* [Requirements.txt-like file for R (Stack Overflow)](https://stackoverflow.com/questions/38928326/is-there-something-like-requirements-txt-for-r) - various suggestions for creating a dependency file for your R project.

## Integrations with other Software

* [Using R and Tableau](https://www.tableau.com/learn/whitepapers/using-r-and-tableau) - Tableau Desktop can now connect to R through calculated fields and take advantage of R functions, libraries, packages and even saved models. These calculations dynamically invoke the R engine and pass values to R via the Rserve package, and are returned back to Tableau.
* [Exploratory.io](https://exploratory.io/) -  Exploratory Desktop provides a Simple and Modern UI experience to access various Data Science functionalities including Data Wrangling, Visualization, Statistics, Machine Learning, Reporting, and Dashboard. It is built on R so you can easily Extend it with thousands of open source packages to meet your needs.
* [JASP](https://jasp-stats.org/) - GUI based in R that allows you to conduct statistical analyses in seconds, without programming. Offers both frequentist and Bayesian analysis methods.
* [Jamovi](https://www.jamovi.org/) - free and open statistical software built on R. Would you like the R code for your analyses? Jamovi can provide that too.

## R + Python

* [Reticulate](https://rstudio.github.io/reticulate/) - R interface to Python
* [Python and R for the Modern Data Scientist (book)](https://www.oreilly.com/library/view/python-and-r/9781492093398/) - This book guides data scientists from the Python and R communities along the path to becoming bilingual. By recognizing the strengths of both languages, you'll discover new ways to accomplish data science tasks and expand your skill set.

## R package repositories
* [ROpenSci](https://ropensci.org/) - help develop R packages for the sciences via community driven learning, review and maintenance of contributed software in the R ecosystem.

## R for Reproducible Research

* [PsyTeachR](https://psyteachr.github.io/) - curriculum that emphasizes essential ‘data science’ graduate skills that have been overlooked in traditional approaches to teaching, including programming skills, data visualisation, data wrangling and reproducible reports.
* [R for Reproducible Research](https://annakrystalli.me/rrresearch/) - This course focuses on data and project management through R and Rstudio, will introduce students to best practice and equip them with modern tools and techniques for managing data and computational workflows to their full potential. 
* [Reproducible Research in R](https://r-cubed.rostools.org/) - An introductory workshop on modern data analyses and workflows.
